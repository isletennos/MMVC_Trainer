{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7-O9IRzogIx"
      },
      "source": [
        "# モデルの精度を確認するためのインターフェース\n",
        "\n",
        "ver.2023/3/15\n",
        "\n",
        "学習したモデルでTTSと非リアルタイムのVCを行い、モデルの精度を検証します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5lhnVQbOIoe"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_XCTZsIKu-t2"
      },
      "outputs": [],
      "source": [
        "#@title ## 0 ノートブックの準備\n",
        "\n",
        "#@markdown このノートブックのセットアップを行います。セルを実行してください。\n",
        "\n",
        "#@markdown 「警告: このノートブックは Google が作成したものではありません。」といったポップアップが表示された場合、内容を確認して「このまま実行」を選択してください。このノートブックでは、外部へのデータ送信は一切行われません。\n",
        "\n",
        "#@markdown セルの実行が完了したら、次に進んでください。\n",
        "\n",
        "#@markdown 「警告: このノートブックは Google が作成したものではありません。」といったポップアップが表示された場合、内容を確認して「このまま実行」を選択してください。このノートブックでは、外部へのデータ送信は一切行われません。\n",
        "\n",
        "#debug用ディレクトリの作成\n",
        "!rm -rf /mmvc-debug\n",
        "!mkdir /mmvc-debug\n",
        "\n",
        "#現在時刻の取得\n",
        "import datetime\n",
        "jst_delta = datetime.timedelta(hours=9)\n",
        "JST = datetime.timezone(jst_delta, 'JST')\n",
        "now = datetime.datetime.now(JST)\n",
        "nowt = now.strftime('%Y%m%d%H%M%S')\n",
        "\n",
        "#出力記録用カスタムマジック %%ccapture\n",
        "from IPython import get_ipython\n",
        "from IPython.core import magic_arguments\n",
        "from IPython.core.magic import register_cell_magic\n",
        "from IPython.utils.capture import capture_output\n",
        "\n",
        "@magic_arguments.magic_arguments()\n",
        "@magic_arguments.argument('output', type=str, default='', nargs='?')\n",
        "\n",
        "@register_cell_magic\n",
        "def ccapture(line, cell):\n",
        "    args = magic_arguments.parse_argstring(ccapture, line)\n",
        "    with capture_output() as outputs:\n",
        "        get_ipython().run_cell(cell)\n",
        "    if args.output:\n",
        "        get_ipython().user_ns[args.output] = outputs\n",
        "    \n",
        "    outputs()\n",
        "\n",
        "#Pythonパッケージのインストール\n",
        "print(\"log: パッケージのインストールを開始します。\")\n",
        "##ipywidgets UIの実装に使用\n",
        "!pip install ipywidgets\n",
        "import ipywidgets as widgets\n",
        "#IPython.display 出力の消去に使用\n",
        "from IPython.display import clear_output\n",
        "#time waitコマンドの実装に使用\n",
        "import time\n",
        "#git-lfs 事前学習済みモデルのダウンロードに使用\n",
        "!apt install git-lfs\n",
        "#os ディレクトリの存在確認に使用\n",
        "import os\n",
        "#sys Pythonの管理全般(クラッシュ、tracebackなど)\n",
        "import sys\n",
        "print(\"log: パッケージのインストールが完了しました。\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OACNuBhwZVZd"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZVPYnCiM_m7r"
      },
      "outputs": [],
      "source": [
        "%%ccapture one_prepare_notebook\n",
        "#@title ## 1 Notebookの準備\n",
        "#@markdown このNotebookの実行に必要なパッケージを導入します。\n",
        "\n",
        "#@markdown 時間がかかりますので、気長にお待ちください。\n",
        "\n",
        "#Pythonパッケージのインストール\n",
        "print(\"log: パッケージのインストールを開始します。\")\n",
        "##ipywidgets UIの実装に使用\n",
        "!pip install ipywidgets\n",
        "import ipywidgets as widgets\n",
        "#IPython.display 出力の消去に使用\n",
        "from IPython.display import clear_output\n",
        "#time waitコマンドの実装に使用\n",
        "import time\n",
        "print(\"log: パッケージのインストールが完了しました。\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J6r05V5eKND"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AY9VJFRv6rnY"
      },
      "outputs": [],
      "source": [
        "%%ccapture two_prepare_repo\n",
        "#@title ## 2 リポジトリの準備\n",
        "#@markdown リポジトリの準備を行います。\n",
        "\n",
        "#@markdown まず、セルを実行してください。UIが表示されます。\n",
        "\n",
        "#@markdown Colabを使用している場合\n",
        "#@markdown * PlatformでColabを選択してください。\n",
        "#@markdown * PathでMMVC_Trainerの保存先となる、Google Driveのマイドライブ以下のパスを指定してください。よく分からない場合は、変更しなくとも構いません。変更しない場合は、マイドライブ直下に保存されます。\n",
        "#@markdown * 「このノートブックに Google ドライブのファイルへのアクセスを許可しますか？」といったポップアップが表示されますので、「Google ドライブに接続」を押下し、google アカウントを選択して、「許可」を選択してください。\n",
        "\n",
        "#@markdown ローカルの場合\n",
        "#@markdown * PlatformでLocalを選択してください。\n",
        "#@markdown * PathでMMVC_Trainerの保存先となる、ローカルのパスを指定してください。\n",
        "\n",
        "#@markdown 設定が完了したら、次へを押してください。\n",
        "\n",
        "\n",
        "#---関数---\n",
        "def mount_googledrive():\n",
        "  print(\"log: Google Driveのマウントを開始します。\")\n",
        "  print(\"「このノートブックに Google ドライブのファイルへのアクセスを許可しますか？」といったポップアップが表示されますので、「Google ドライブに接続」を押下し、google アカウントを選択して、「許可」を選択してください。\")\n",
        "  time.sleep(2)\n",
        "  print(\"info: 少し時間がかかります。このままお待ちください。\")\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"log: Google Driveのマウントが完了しました。\\n\")\n",
        "\n",
        "#---関数終わり---\n",
        "\n",
        "def first_view():\n",
        "  #widgetsの構成\n",
        "  global platform_input #グローバル指定\n",
        "  global path_input #グローバル指定\n",
        "  platform_input = widgets.Dropdown(options=[\"Colab\", \"Local\"], value=\"Colab\", description='Platform:', disabled=False)\n",
        "  path_input = widgets.Text(value='/content/drive/MyDrive/MMVC_Trainer-v1.5.0.0_SiFiGAN', placeholder='/content/drive/MyDrive/MMVC_Trainer-v1.5.0.0_SiFiGAN', description='Path:', disabled=False)\n",
        "  next_1 = widgets.Button(description='次へ', disabled=False)\n",
        "  #widgetsの表示\n",
        "  display(platform_input, path_input, next_1)\n",
        "  #ボタンがクリックされたらmainを動かす\n",
        "  next_1.on_click(main)\n",
        "\n",
        "def main(b: widgets.Button) -> None:\n",
        "  clear_output(True)\n",
        "  #入力を変数に入れておく\n",
        "  global platform #グローバル指定\n",
        "  platform = platform_input.value\n",
        "  global path #グローバル指定\n",
        "  path = path_input.value\n",
        "  #Colabとそれ以外で処理を分ける\n",
        "  if platform == \"Colab\":\n",
        "    mount_googledrive() #Google Driveのマウント\n",
        "    %cd $path\n",
        "  elif platform == \"Local\":\n",
        "    %cd $path\n",
        "\n",
        "#実行\n",
        "first_view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0uxP82wDGg3"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oOWo15aRewCk"
      },
      "outputs": [],
      "source": [
        "%%ccapture three_install_library\n",
        "#@title ## 3 ライブラリのインストール\n",
        "#@markdown 実行に必要なライブラリを導入します。\n",
        "\n",
        "#@markdown 時間がかかりますので、気長にお待ちください。\n",
        "\n",
        "!apt-get install espeak\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import create_dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio\n",
        "import numpy as np \n",
        "\n",
        "import commons\n",
        "import utils\n",
        "from data_utils import TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
        "from models import SynthesizerTrn\n",
        "from scipy.io.wavfile import write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjrZ1vGvFFqt"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rm-3oWmarsZt"
      },
      "outputs": [],
      "source": [
        "%%ccapture four_load_model\n",
        "#@title ## 4 学習したモデルの読み込み\n",
        "#@markdown 学習したモデルを読み込みます。\n",
        "\n",
        "#@markdown まず、セルを実行してください。\n",
        "\n",
        "#@markdown UIが表示されますので、以下の説明に従って設定を行ってください。\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown CONFIG_PATH：configファイルのパス\n",
        "#@markdown 作成したconfigファイル(json)を指定してください。  \n",
        "#@markdown `configs/****.json` のような値になります。\n",
        "\n",
        "#@markdown NET_PATH：学習したモデルのパス\n",
        "#@markdown 作成されたモデル(pth)を指定してください。\n",
        "#@markdown `logs/xxxxxxxx_xxxxx/G_xxxxx.pth` のような値になります。\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown 設定が完了したら、次へを押してください。\n",
        "\n",
        "def first_view():\n",
        "  #widgetsの構成\n",
        "  global CONFIG_PATH_input #グローバル指定\n",
        "  global NET_PATH_input #グローバル指定\n",
        "  CONFIG_PATH_input = widgets.Text(value='configs/train_config.json', placeholder='configs/train_config.json', description='config_path:', disabled=False)\n",
        "  NET_PATH_input = widgets.Text(value='logs/20220306_24000/G_best.pth', placeholder='logs/20220306_24000/G_best.pth', description='net_path:', disabled=False)\n",
        "  next_1 = widgets.Button(description='次へ', disabled=False)\n",
        "  #widgetsの表示\n",
        "  display(CONFIG_PATH_input, NET_PATH_input, next_1)\n",
        "  #ボタンがクリックされたらmainを動かす\n",
        "  next_1.on_click(main)\n",
        "\n",
        "def main(b: widgets.Button) -> None:\n",
        "  clear_output(True)\n",
        "  #入力を変数に入れておく\n",
        "  global CONFIG_PATH #グローバル指定\n",
        "  CONFIG_PATH = CONFIG_PATH_input.value\n",
        "  global NET_PATH #グローバル指定\n",
        "  NET_PATH = NET_PATH_input.value\n",
        "  #モデルの読み込み\n",
        "  global hps\n",
        "  hps = utils.get_hparams_from_file(CONFIG_PATH)\n",
        "  global net_g\n",
        "  net_g = SynthesizerTrn(\n",
        "      spec_channels = hps.data.filter_length // 2 + 1,\n",
        "      segment_size = hps.train.segment_size // hps.data.hop_length,\n",
        "      inter_channels = hps.model.inter_channels,\n",
        "      hidden_channels = hps.model.hidden_channels,\n",
        "      upsample_rates = hps.model.upsample_rates,\n",
        "      upsample_initial_channel = hps.model.upsample_initial_channel,\n",
        "      upsample_kernel_sizes = hps.model.upsample_kernel_sizes,\n",
        "      n_flow = hps.model.n_flow,\n",
        "      dec_out_channels=1,\n",
        "      dec_kernel_size=7,\n",
        "      n_speakers = hps.data.n_speakers,\n",
        "      gin_channels = hps.model.gin_channels,\n",
        "      requires_grad_pe = hps.requires_grad.pe,\n",
        "      requires_grad_flow = hps.requires_grad.flow,\n",
        "      requires_grad_text_enc = hps.requires_grad.text_enc,\n",
        "      requires_grad_dec = hps.requires_grad.dec\n",
        "      )\n",
        "  _ = net_g.eval()\n",
        "  _ = utils.load_checkpoint(NET_PATH, net_g, True, None)\n",
        "  print(\"log: モデルの読み込みが完了しました\")\n",
        "\n",
        "#実行\n",
        "first_view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcbrw5CPGucf"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ccapture five_vc\n",
        "#@title ## 5 学習したモデルで非リアルタイムVCを行う(学習に利用した音声ファイル)\n",
        "#@markdown 非リアルタイムのVCを行います。\n",
        "\n",
        "#@markdown まず、セルを実行してください。\n",
        "\n",
        "#@markdown UIが表示されますので、以下の説明に従って設定を行ってください。\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown SOURCE_SPEAKER_ID\n",
        "#@markdown ソース話者のID\n",
        "\n",
        "#@markdown SOURCE_WAVFILE\n",
        "#@markdown ソース話者の音声ファイルのパス\n",
        "#@markdown 学習に使用した音声ファイルのうちいずれか一つを指定してください。\n",
        "\n",
        "#@markdown TARGET_ID\n",
        "#@markdown ターゲット話者のID\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown 設定が完了したら、次へを押してください。\n",
        "#@markdown 変換が行われ、変換後の音声が出力されます。\n",
        "\n",
        "#@markdown VCの性能が悪い場合、学習不足か他に問題があります。\n",
        "\n",
        "\n",
        "def first_view():\n",
        "  #widgetsの構成\n",
        "  global SOURCE_SPEAKER_ID_input #グローバル指定\n",
        "  global SOURCE_WAVFILE_input #グローバル指定\n",
        "  global TARGET_ID_input #グローバル指定\n",
        "  global f0_scale_input #グローバル指定\n",
        "  SOURCE_SPEAKER_ID_input = widgets.IntText(value='0', placeholder='0', description='SOURCE_SPEAKER_ID:', disabled=False)\n",
        "  SOURCE_WAVFILE_input = widgets.Text(value='dataset/00_myvoice/wav/VOICEACTRESS100_001.wav', placeholder='dataset/00_myvoice/wav/VOICEACTRESS100_001.wav', description='SOURCE_WAVFILE:', disabled=False)\n",
        "  TARGET_ID_input = widgets.IntText(value='101', placeholder='101', description='TARGET_ID:', disabled=False)\n",
        "  f0_scale_input = widgets.FloatSlider(value='2.0', min='0.1', max='5.0', step='0.1', description='f0_scale:', disabled=False)\n",
        "  next_1 = widgets.Button(description='次へ', disabled=False)\n",
        "  #widgetsの表示\n",
        "  display(SOURCE_SPEAKER_ID_input, SOURCE_WAVFILE_input, TARGET_ID_input, f0_scale_input, next_1)\n",
        "  #ボタンがクリックされたらmainを動かす\n",
        "  next_1.on_click(main)\n",
        "\n",
        "def main(b: widgets.Button) -> None:\n",
        "  clear_output(True)\n",
        "  #入力を変数に入れておく\n",
        "  global SOURCE_SPEAKER_ID #グローバル指定\n",
        "  SOURCE_SPEAKER_ID = SOURCE_SPEAKER_ID_input.value\n",
        "  global SOURCE_WAVFILE #グローバル指定\n",
        "  SOURCE_WAVFILE = SOURCE_WAVFILE_input.value\n",
        "  global SOURCE_WAVFILE_id #グローバル指定\n",
        "  SOURCE_WAVFILE_id = SOURCE_WAVFILE.split(\"/\")[1]\n",
        "  global SOURCE_WAVFILE_filename #グローバル指定\n",
        "  SOURCE_WAVFILE_filename = SOURCE_WAVFILE.split(\"/\")[-1].split(\".\")[0]\n",
        "  global TARGET_ID #グローバル指定\n",
        "  TARGET_ID = TARGET_ID_input.value\n",
        "  global DUMMY #グローバル指定\n",
        "  DUMMY = \"dataset_etc/units/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global F0 #グローバル指定\n",
        "  F0 = \"dataset_etc/F0/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global CF0 #グローバル指定\n",
        "  CF0 = \"dataset_etc/cF0/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global f0_scale #グローバル指定\n",
        "  f0_scale = f0_scale_input.value\n",
        "\n",
        "  with torch.no_grad():\n",
        "    dataset = TextAudioSpeakerLoader(hps.data.training_files_notext, hps.data)\n",
        "    data = dataset.get_audio_text_speaker_pair([SOURCE_WAVFILE, SOURCE_SPEAKER_ID, DUMMY, F0, CF0])\n",
        "    data = TextAudioSpeakerCollate(\n",
        "      sample_rate = hps.data.sampling_rate,\n",
        "      segment_size = hps.train.segment_size,\n",
        "      hop_size = hps.data.hop_length,\n",
        "      df_f0_type = hps.data.df_f0_type,\n",
        "      dense_factors = hps.data.dense_factors,\n",
        "      upsample_scales = hps.model.upsample_rates,\n",
        "      sine_amp = hps.data.sine_amp,\n",
        "      noise_amp = hps.data.noise_amp,\n",
        "      sine_f0_type = hps.data.sine_f0_type,\n",
        "      signal_types = hps.data.signal_types,\n",
        "      train = False,\n",
        "      f0_factor = f0_scale,\n",
        "  )([data])\n",
        "    x, x_lengths, spec, spec_lengths, y, y_lengths, sid_src, f0, f0_lengths, sin, d, slice_id = [x for x in data]\n",
        "    sid_tgt1 = torch.LongTensor([TARGET_ID])\n",
        "    audio1 = net_g.voice_conversion(spec, spec_lengths, f0, sid_src=sid_src, sid_tgt=sid_tgt1)[0][0,0].data.cpu().float().numpy()\n",
        "    print(\"Original SID: %d\" % sid_src.item())\n",
        "    ipd.display(ipd.Audio(y[0].cpu().numpy(), rate=hps.data.sampling_rate,normalize = False))\n",
        "    print(\"Converted SID: %d\" % sid_tgt1.item())\n",
        "    ipd.display(ipd.Audio(audio1, rate=hps.data.sampling_rate,normalize = False))\n",
        "\n",
        "#実行\n",
        "first_view()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z-R9EULDnbKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uEqm8yA6v9xz"
      },
      "outputs": [],
      "source": [
        "%%ccapture six_vc\n",
        "#@title ## 6 学習したモデルで非リアルタイムVCを行う(学習に利用していない音声ファイル)\n",
        "#@markdown 非リアルタイムのVCを行います。\n",
        "\n",
        "#@markdown まず、セルを実行してください。\n",
        "\n",
        "#@markdown UIが表示されますので、以下の説明に従って設定を行ってください。\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown SOURCE_SPEAKER_ID\n",
        "#@markdown ソース話者のID\n",
        "\n",
        "#@markdown SOURCE_WAVFILE\n",
        "#@markdown ソース話者の音声ファイルのパス\n",
        "#@markdown 学習に使用した音声ファイルのうちいずれか一つを指定してください。\n",
        "\n",
        "#@markdown TARGET_ID\n",
        "#@markdown ターゲット話者のID\n",
        "\n",
        "#@markdown ​\n",
        "\n",
        "#@markdown 設定が完了したら、次へを押してください。\n",
        "#@markdown 変換が行われ、変換後の音声が出力されます。\n",
        "\n",
        "#@markdown VCの性能が悪い場合、学習不足か他に問題があります。\n",
        "\n",
        "\n",
        "def first_view():\n",
        "  #widgetsの構成\n",
        "  global SOURCE_SPEAKER_ID_input #グローバル指定\n",
        "  global SOURCE_WAVFILE_input #グローバル指定\n",
        "  global TARGET_ID_input #グローバル指定\n",
        "  global f0_scale_input #グローバル指定\n",
        "  SOURCE_SPEAKER_ID_input = widgets.IntText(value='0', placeholder='0', description='SOURCE_SPEAKER_ID:', disabled=False)\n",
        "  SOURCE_WAVFILE_input = widgets.Text(value='dataset/00_myvoice/wav/VOICEACTRESS100_001.wav', placeholder='dataset/00_myvoice/wav/VOICEACTRESS100_001.wav', description='SOURCE_WAVFILE:', disabled=False)\n",
        "  TARGET_ID_input = widgets.IntText(value='101', placeholder='101', description='TARGET_ID:', disabled=False)\n",
        "  f0_scale_input = widgets.FloatSlider(value='2.0', min='0.1', max='5.0', step='0.1', description='f0_scale:', disabled=False)\n",
        "  next_1 = widgets.Button(description='次へ', disabled=False)\n",
        "  #widgetsの表示\n",
        "  display(SOURCE_SPEAKER_ID_input, SOURCE_WAVFILE_input, TARGET_ID_input, f0_scale_input, next_1)\n",
        "  #ボタンがクリックされたらmainを動かす\n",
        "  next_1.on_click(main)\n",
        "\n",
        "def main(b: widgets.Button) -> None:\n",
        "  clear_output(True)\n",
        "  #入力を変数に入れておく\n",
        "  global SOURCE_SPEAKER_ID #グローバル指定\n",
        "  SOURCE_SPEAKER_ID = SOURCE_SPEAKER_ID_input.value\n",
        "  global SOURCE_WAVFILE #グローバル指定\n",
        "  SOURCE_WAVFILE = SOURCE_WAVFILE_input.value\n",
        "  global SOURCE_WAVFILE_id #グローバル指定\n",
        "  SOURCE_WAVFILE_id = SOURCE_WAVFILE.split(\"/\")[1]\n",
        "  global SOURCE_WAVFILE_filename #グローバル指定\n",
        "  SOURCE_WAVFILE_filename = SOURCE_WAVFILE.split(\"/\")[-1].split(\".\")[0]\n",
        "  global TARGET_ID #グローバル指定\n",
        "  TARGET_ID = TARGET_ID_input.value\n",
        "  global DUMMY #グローバル指定\n",
        "  DUMMY = \"dataset_etc/units/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global F0 #グローバル指定\n",
        "  F0 = \"dataset_etc/F0/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global CF0 #グローバル指定\n",
        "  CF0 = \"dataset_etc/cF0/\" + SOURCE_WAVFILE_id + \"/\" + SOURCE_WAVFILE_filename + \".npy\"\n",
        "  global f0_scale #グローバル指定\n",
        "  f0_scale = f0_scale_input.value\n",
        "\n",
        "  hubert = torch.hub.load(\"bshall/hubert:main\", \"hubert_soft\")\n",
        "  with torch.no_grad():\n",
        "    source, sr = torchaudio.load(SOURCE_WAVFILE)\n",
        "    source = source.unsqueeze(0)\n",
        "    units = hubert.units(source).numpy().squeeze(0)\n",
        "    f0 = create_dataset.get_f0(SOURCE_WAVFILE, frame_length=512, win_length=256, hop_length=128)\n",
        "    _, cf0, _ = create_dataset.convert_continuos_f0(f0)\n",
        "    cf0_mean = np.mean(cf0)\n",
        "    text = torch.FloatTensor(units)\n",
        "    sid = torch.LongTensor([SOURCE_SPEAKER_ID])\n",
        "    dataset = TextAudioSpeakerLoader(hps.data.training_files_notext, hps.data)\n",
        "    spec, wav = dataset.get_audio(SOURCE_WAVFILE)\n",
        "    f0 = torch.FloatTensor(f0)\n",
        "    cf0 = torch.FloatTensor(cf0)\n",
        "    data = (text, spec, wav, sid, f0, cf0)\n",
        "    data = TextAudioSpeakerCollate(\n",
        "      sample_rate = hps.data.sampling_rate,\n",
        "      segment_size = hps.train.segment_size,\n",
        "      hop_size = hps.data.hop_length,\n",
        "      df_f0_type = hps.data.df_f0_type,\n",
        "      dense_factors = hps.data.dense_factors,\n",
        "      upsample_scales = hps.model.upsample_rates,\n",
        "      sine_amp = hps.data.sine_amp,\n",
        "      noise_amp = hps.data.noise_amp,\n",
        "      sine_f0_type = hps.data.sine_f0_type,\n",
        "      signal_types = hps.data.signal_types,\n",
        "      train = False,\n",
        "      f0_factor = f0_scale,\n",
        "  )([data])\n",
        "    x, x_lengths, spec, spec_lengths, y, y_lengths, sid_src, f0, f0_lengths, sin, d, slice_id = [x for x in data]\n",
        "    sid_tgt1 = torch.LongTensor([TARGET_ID])\n",
        "    audio1 = net_g.voice_conversion(spec, spec_lengths, , sid_src=sid_src, sid_tgt=sid_tgt1)[0,0].data.cpu().float().numpy()\n",
        "    print(\"Original SID: %d\" % sid_src.item())\n",
        "    ipd.display(ipd.Audio(y[0].cpu().numpy(), rate=hps.data.sampling_rate,normalize = False))\n",
        "    print(\"Converted SID: %d\" % sid_tgt1.item())\n",
        "    ipd.display(ipd.Audio(audio1, rate=hps.data.sampling_rate,normalize = False))\n",
        "\n",
        "#実行\n",
        "first_view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBvOKa9eJFjJ"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08CW8VAygNyH"
      },
      "source": [
        "## サポート専用\n",
        "\n",
        "**以下はお問い合わせの際、指示があった場合のみ使用してください。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "737DzMeregPQ"
      },
      "outputs": [],
      "source": [
        "#@markdown **このセルは無視してください。**\n",
        "\n",
        "#@markdown このセルは、セルが一括で実行されることを防ぐためのものです。\n",
        "\n",
        "#@markdown  実行してしまった場合は、左側のアイコンをクリックしてセルを終了してください。\n",
        "\n",
        "#一括実行の阻止\n",
        "import time\n",
        "time.sleep(86400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5ZIR8wfmrx"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCOgnUaVI1eN"
      },
      "outputs": [],
      "source": [
        "#@title ## サポート用ファイルの作成\n",
        "\n",
        "#@markdown セルを実行すると内部処理が行われ、zipファイルが操作中のPC(またはタブレットなど)にダウンロードされます。\n",
        "\n",
        "#@markdown ダウンロードされるzipファイルには、以下のファイルや情報が含まれます。\n",
        "\n",
        "#@markdown * MMVC_Trainerフォルダ内のファイルの一覧\n",
        "#@markdown * このノートブックで使用されている変数のリスト\n",
        "#@markdown * このセッション内の出力\n",
        "#@markdown * configsフォルダ内及びlogsフォルダ内のファイル\n",
        "#@markdown * version.txt (MMVCのバージョンが記載されているファイル)\n",
        "\n",
        "#@markdown これらには、ユーザーの個人情報が含まれる可能性があります。ダウンロード完了後、ファイルを共有する前に、必ず内容をご確認ください。\n",
        "\n",
        "#@markdown ファイルのダウンロードが完了したら、ランタイムを切断してください。\n",
        "\n",
        "#ファイルの準備\n",
        "variable_txt = \"/mmvc-debug/mmvc-\" + str(nowt) + \"-variable.txt\"\n",
        "tree_dic_txt = \"/mmvc-debug/mmvc-\" + str(nowt) + \"-tree_dic.txt\"\n",
        "version_txt = \"/mmvc-debug/mmvc-\" + str(nowt) + \"-version_txt.txt\"\n",
        "export_zip = \"/mmvc-debug-\" + str(nowt)\n",
        "export_zipp = \"/mmvc-debug-\" + str(nowt) + \".zip\"\n",
        "\n",
        "#変数の値を保存\n",
        "#whos使うと長い文字列が省略されるため、変数毎に取得する\n",
        "##変数の一覧を取得\n",
        "vlist = %who_ls\n",
        "##それぞれの変数で値を取得してファイルに保存\n",
        "with open(variable_txt, 'w') as f:\n",
        "  for ev in vlist:\n",
        "    try:\n",
        "      #変数名(str)\n",
        "      print(ev, end=' : ', file=f) \n",
        "      #変数の型(変数名がstrとなっているためevalでkeyに直す)\n",
        "      print(type(eval(ev)), end=' : ', file=f)\n",
        "      #変数の内容(変数名がstrとなっているためevalでkeyに直す)\n",
        "      print(eval(ev), file=f)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "#tree\n",
        "!apt install tree\n",
        "##ディレクトリ内以下\n",
        "import traceback\n",
        "with open(tree_dic_txt, 'w') as f:\n",
        "  try:\n",
        "    !tree {path} > {tree_dic_txt}\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred!\", file=f)\n",
        "    print(e, file=f)\n",
        "    print(traceback.print_exc(), file=f)\n",
        "\n",
        "#version.txtの保存\n",
        "try:\n",
        "  !cp {path}/version.txt {version_txt}\n",
        "except:\n",
        "  pass\n",
        "\n",
        "#logsとconfigsの保存\n",
        "#directoryが無かったらmkdirしてno-dic.txt置く\n",
        "!if [ -d {path}/logs ]; then if [ -z \"$(ls {path}/logs)\" ]; then touch {path}/logs/no-file.txt;else find . -name \"*.log\" -exec cp {} ~/mmvc-debug/logs \\;; fi;else mkdir /mmvc-debug/logs && touch /mmvc-debug/logs/no-dic.txt; fi\n",
        "!if [ -d {path}/configs ]; then if [ -z \"$(ls {path}/configs)\" ]; then touch {path}/configs/no-file.txt;else cp -rp {path}/configs /mmvc-debug/configs; fi;else mkdir /mmvc-debug/configs && touch /mmvc-debug/configs/no-dic.txt; fi\n",
        "\n",
        "#直近のtracebackの保存\n",
        "with open('/mmvc-debug/traceback.txt', 'w') as f:\n",
        "  try:\n",
        "    print(sys.last_type, sys.last_value, sys.last_traceback, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "#ccaptureの保存\n",
        "!mkdir /mmvc-debug/ccapture\n",
        "with open('/mmvc-debug/ccapture/one_prepare_notebook.txt', 'w') as f:\n",
        "  try:\n",
        "    print(one_prepare_notebook, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('/mmvc-debug/ccapture/two_prepare_repo.txt', 'w') as f:\n",
        "  try:\n",
        "    print(two_prepare_repo, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('/mmvc-debug/ccapture/three_install_library.txt', 'w') as f:\n",
        "  try:\n",
        "    print(three_install_library, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('/mmvc-debug/ccapture/four_load_model.txt', 'w') as f:\n",
        "  try:\n",
        "    print(four_load_model, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('/mmvc-debug/ccapture/five_vc.txt', 'w') as f:\n",
        "  try:\n",
        "    print(five_vc, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('/mmvc-debug/ccapture/six_vc.txt', 'w') as f:\n",
        "  try:\n",
        "    print(six_vc, file=f)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "#zipにまとめる\n",
        "!apt install zip\n",
        "!zip {export_zip} -r /mmvc-debug\n",
        "\n",
        "#colabのfilesモジュールを使ってダウンロード\n",
        "from google.colab import files\n",
        "files.download(export_zipp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3394867249fd41ee68869925f4586b97ae8a94f3c93a4c25403e9e75f272611"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
