{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7-O9IRzogIx"
      },
      "source": [
        "# モデルの精度を確認するためのインターフェース\n",
        "\n",
        "ver.2022/12/19\n",
        "\n",
        "「Train_MMVC.ipynb」で学習したモデルでTTSと非リアルタイムのVCを行い、モデルの精度を検証します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5lhnVQbOIoe"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jFsXIyuIzHGX"
      },
      "outputs": [],
      "source": [
        "#@title ## 1 Google Driveをマウント\n",
        "#@markdown **このノートブックで、Google Driveを使用するための設定です。**\n",
        "\n",
        "#@markdown 「警告: このノートブックは Google が作成したものではありません。」といったポップアップが表示された場合、内容を確認して「このまま実行」を選択してください。このノートブックでは、外部へのデータ送信は一切行われません。\n",
        "\n",
        "#@markdown 　「このノートブックに Google ドライブのファイルへのアクセスを許可しますか？」といったポップアップが表示されるので、「Google ドライブに接続」を押下し、google アカウントを選択して、「許可」を選択してください。\n",
        "\n",
        "#@markdown 成功すれば、下記メッセージが出ます。\n",
        "\n",
        "#@markdown ``` \n",
        "#@markdown Mounted at /content/drive/\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNnKrsdIDE6s"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4dSgFEkpvEhj"
      },
      "outputs": [],
      "source": [
        "#@title 2 MMVC_Trainerディレクトリに移動\n",
        "#@markdown ​マウントしたGoogle DriveのMMVC_Trainerディレクトリに移動します。\n",
        "\n",
        "#@markdown Google DriveでMMVC_Trainerの場所を確認し、以下でパスを指定してください。\n",
        "\n",
        "#@markdown 正しいパスが指定されていれば、以下のようなメッセージが表示されます。\n",
        "\n",
        "#@markdown ```\n",
        "#@markdown attentions.py\n",
        "#@markdown commons.py\n",
        "#@markdown ...(略)\n",
        "#@markdown ```\n",
        "#@markdown\n",
        "\n",
        "\n",
        "#@markdown ​\n",
        "#@markdown ### Settings\n",
        "directory = \"/content/drive/MyDrive/MMVC_Trainer\" #@param {type:\"string\"}\n",
        "\n",
        "%cd $directory\n",
        "!ls -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0uxP82wDGg3"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oOWo15aRewCk"
      },
      "outputs": [],
      "source": [
        "#@title ## 3 ライブラリのインストール\n",
        "#@markdown 時間がかかります。気長にお待ちください。\n",
        "!apt-get install espeak\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import commons\n",
        "import utils\n",
        "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
        "from models import SynthesizerTrn\n",
        "from text.symbols import symbols\n",
        "from text import text_to_sequence\n",
        "\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "def get_text(text, hps):\n",
        "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
        "    if hps.data.add_blank:\n",
        "        text_norm = commons.intersperse(text_norm, 0)\n",
        "    text_norm = torch.LongTensor(text_norm)\n",
        "    return text_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjrZ1vGvFFqt"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rm-3oWmarsZt"
      },
      "outputs": [],
      "source": [
        "#@title ## 4 学習したモデルの読み込み\n",
        "#@markdown 学習したモデルを読み込みます。以下のSettingsで必要な設定を行った後、セルを実行してください。\n",
        "\n",
        "#@markdown ​\n",
        "#@markdown ### Settings\n",
        "#@markdown CONFIG_PATH：configファイルのパス\n",
        "#@markdown 作成したconfigファイル(json)を指定してください。  \n",
        "#@markdown `configs/****.json` のような値になります。\n",
        "CONFIG_PATH = \"configs/train_config.json\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown NET_PATH：学習したモデルのパス\n",
        "#@markdown 作成されたモデル(pth)を指定してください。\n",
        "#@markdown `logs/xxxxxxxx_xxxxx/G_xxxxx.pth` のような値になります。\n",
        "NET_PATH = \"logs/20220306_24000/G_xxxxx.pth\"  #@param {type:\"string\"}\n",
        "\n",
        "hps = utils.get_hparams_from_file(CONFIG_PATH)\n",
        "\n",
        "net_g = SynthesizerTrn(\n",
        "    len(symbols),\n",
        "    hps.data.filter_length // 2 + 1,\n",
        "    hps.train.segment_size // hps.data.hop_length,\n",
        "    n_speakers=hps.data.n_speakers,\n",
        "    **hps.model)\n",
        "_ = net_g.eval()\n",
        "\n",
        "_ = utils.load_checkpoint(NET_PATH, net_g, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcbrw5CPGucf"
      },
      "source": [
        "​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uEqm8yA6v9xz"
      },
      "outputs": [],
      "source": [
        "#@title ## 5 学習したモデルで非リアルタイムVCを行う\n",
        "#@markdown 非リアルタイムのVCを行います。以下のSettingsで必要な設定を行った後、セルを実行してください。\n",
        "\n",
        "#@markdown 性能が悪い場合、学習不足か他に問題があります。\n",
        "\n",
        "#@markdown ​\n",
        "#@markdown ### Settings\n",
        "#@markdown SOURCE_SPEAKER_ID\n",
        "#@markdown ソース話者のID\n",
        "SOURCE_SPEAKER_ID = 107 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown SOURCE_WAVFILE\n",
        "#@markdown ソース話者の音声ファイルのパス\n",
        "#@markdown 学習に使用した音声ファイルか、新規に録音した音声ファイルを指定してください。\n",
        "SOURCE_WAVFILE = \"dataset/textful/00_myvoice/wav/VOICEACTRESS100_001.wav\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown TARGET_ID\n",
        "#@markdown ターゲット話者のID\n",
        "TARGET_ID = 100 #@param {type:\"integer\"}\n",
        "\n",
        "with torch.no_grad():\n",
        "    dataset = TextAudioSpeakerLoader(hps.data.validation_files_notext, hps.data)\n",
        "    data = dataset.get_audio_text_speaker_pair([SOURCE_WAVFILE, SOURCE_SPEAKER_ID, \"a\"])\n",
        "    data = TextAudioSpeakerCollate()([data])\n",
        "    x, x_lengths, spec, spec_lengths, y, y_lengths, sid_src = [x for x in data]\n",
        "    sid_tgt1 = torch.LongTensor([TARGET_ID])\n",
        "    audio1 = net_g.voice_conversion(spec, spec_lengths, sid_src=sid_src, sid_tgt=sid_tgt1)[0][0,0].data.cpu().float().numpy()\n",
        "print(\"Original SID: %d\" % sid_src.item())\n",
        "ipd.display(ipd.Audio(y[0].cpu().numpy(), rate=hps.data.sampling_rate))\n",
        "print(\"Converted SID: %d\" % sid_tgt1.item())\n",
        "ipd.display(ipd.Audio(audio1, rate=hps.data.sampling_rate))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "03_MMVC_Interface.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3394867249fd41ee68869925f4586b97ae8a94f3c93a4c25403e9e75f272611"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}